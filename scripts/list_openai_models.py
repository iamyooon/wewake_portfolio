#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""OpenAI APIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""

import os
import sys
import requests
from pathlib import Path

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
PROJECT_ROOT = Path(__file__).parent.parent
ENV_FILE = PROJECT_ROOT / ".env"

if ENV_FILE.exists():
    encodings = ['utf-8', 'utf-8-sig', 'cp949', 'latin-1']
    content = None
    for encoding in encodings:
        try:
            with open(ENV_FILE, 'r', encoding=encoding) as f:
                content = f.read()
                break
        except UnicodeDecodeError:
            continue
    
    if content:
        for line in content.splitlines():
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                os.environ[key.strip()] = value.strip()

api_key = os.environ.get('OPENAI_API_KEY')
if not api_key:
    print("[ERROR] OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print(f"   {ENV_FILE} íŒŒì¼ì— OPENAI_API_KEY=your-key í˜•ì‹ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    sys.exit(1)

print("=" * 60)
print("OpenAI API ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ")
print("=" * 60)

# OpenAI Models API ì—”ë“œí¬ì¸íŠ¸
url = "https://api.openai.com/v1/models"
headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}

try:
    print("\n[1] Models API ì—”ë“œí¬ì¸íŠ¸ë¡œ ì¡°íšŒ ì¤‘...")
    response = requests.get(url, headers=headers, timeout=30)
    
    if response.status_code == 200:
        models_data = response.json()
        models = models_data.get('data', [])
        print(f"âœ… ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìˆ˜: {len(models)}")
        print("\n" + "=" * 60)
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")
        print("=" * 60)
        
        # ëª¨ë¸ì„ IDë¡œ ì •ë ¬
        models_sorted = sorted(models, key=lambda x: x.get('id', ''))
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
        gpt_models = []
        other_models = []
        
        for model in models_sorted:
            model_id = model.get('id', 'Unknown')
            created = model.get('created', 'Unknown')
            owned_by = model.get('owned_by', 'Unknown')
            
            if 'gpt' in model_id.lower():
                gpt_models.append((model_id, created, owned_by))
            else:
                other_models.append((model_id, created, owned_by))
        
        # GPT ëª¨ë¸ ì¶œë ¥
        if gpt_models:
            print("\nğŸ“ GPT ëª¨ë¸:")
            print("-" * 60)
            for model_id, created, owned_by in gpt_models:
                # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë‚ ì§œë¡œ ë³€í™˜
                if isinstance(created, int):
                    from datetime import datetime
                    try:
                        created_date = datetime.fromtimestamp(created).strftime('%Y-%m-%d')
                    except:
                        created_date = str(created)
                else:
                    created_date = str(created)
                
                print(f"  â€¢ {model_id}")
                print(f"    - ìƒì„±ì¼: {created_date}")
                print(f"    - ì†Œìœ ì: {owned_by}")
                print()
        
        # ê¸°íƒ€ ëª¨ë¸ ì¶œë ¥
        if other_models:
            print("\nğŸ”§ ê¸°íƒ€ ëª¨ë¸:")
            print("-" * 60)
            for model_id, created, owned_by in other_models:
                if isinstance(created, int):
                    from datetime import datetime
                    try:
                        created_date = datetime.fromtimestamp(created).strftime('%Y-%m-%d')
                    except:
                        created_date = str(created)
                else:
                    created_date = str(created)
                
                print(f"  â€¢ {model_id}")
                print(f"    - ìƒì„±ì¼: {created_date}")
                print(f"    - ì†Œìœ ì: {owned_by}")
                print()
        
        # ìš”ì•½ ì •ë³´
        print("=" * 60)
        print("ìš”ì•½")
        print("=" * 60)
        print(f"ì´ ëª¨ë¸ ìˆ˜: {len(models)}")
        print(f"GPT ëª¨ë¸ ìˆ˜: {len(gpt_models)}")
        print(f"ê¸°íƒ€ ëª¨ë¸ ìˆ˜: {len(other_models)}")
        
        # ìµœì‹  GPT ëª¨ë¸ ì¶”ì²œ
        if gpt_models:
            print("\nğŸ’¡ ì¶”ì²œ ëª¨ë¸ (ìµœì‹  ìˆœ):")
            # ìƒì„±ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
            gpt_sorted = sorted(gpt_models, key=lambda x: x[1] if isinstance(x[1], int) else 0, reverse=True)
            for i, (model_id, _, _) in enumerate(gpt_sorted[:5], 1):
                print(f"  {i}. {model_id}")
        
    elif response.status_code == 401:
        print("âŒ ì¸ì¦ ì‹¤íŒ¨ (401): API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print(f"   ì‘ë‹µ: {response.text[:200]}")
    elif response.status_code == 403:
        print("âŒ ê¶Œí•œ ì—†ìŒ (403): API í‚¤ì— ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì‘ë‹µ: {response.text[:200]}")
    else:
        print(f"âŒ HTTP {response.status_code}: {response.text[:200]}")
        response.raise_for_status()
        
except requests.exceptions.RequestException as e:
    print(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    import traceback
    print(traceback.format_exc()[:500])
